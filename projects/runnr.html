<div id="custom-content" class="white-popup-block">
    <div class="content">
        <div class="slider-content">
            <div id="project-slider" class="owl-carousel">
                <div class="item"><img class="img-responsive" src="images/folio/runnr1.jpg"></div>
                <div class="item"><img class="img-responsive" src="images/folio/runnr2.jpg"></div>
                <div class="item-video">
                    <div class="videoWrapper">
                        <!-- Copy & Pasted from YouTube -->
                        <iframe width="560" height="349" src="https://www.youtube.com/embed/Ut6tXiMbBuc" frameborder="0"
                                allowfullscreen></iframe>
                    </div>
                </div>
            </div>
        </div>
        <div class="clear"></div>
        <div class="container">
            <div class="separator"></div>
            <h2>RUNNR (Experimental User Interfaces)</h2>
            <h4 class="margin">Design - Prototyping - Hardware - Software</h4>
            <p>Designed and developed a running assistant that uses haptic feedback and tapping interface to completely
                control a users running dynamics. An <span class="pbold">Arduino</span> was used to measure the impact and speed of a user's run and
                based on the user preferences sends subtle signals through the haptic motors attached to his body to
                adjust his motion. An <span class="pbold">Android application</span> was developed to adjust and monitor the run mechanism of the
                user. The project was inspired after user-research where it was found that there is no non-intrusive way
                to control run training. Also, improper impact while landing might result in injuries which can be
                avoided by proper monitoring. </p>
            <!--<a href="#" class="lanch-button transition " target="_blank">Launch project</a>-->
        </div>
    </div>
</div>
